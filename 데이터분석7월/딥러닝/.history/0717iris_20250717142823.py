import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras.utils import to_categorical
tf

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
iris = load_iris()
X = iris.data              # 4ê°œì˜ íŠ¹ì„±
y = iris.target            # 3ê°œì˜ í´ë˜ìŠ¤: 0, 1, 2

# 2. ì „ì²˜ë¦¬
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# 4. One-hot encoding
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# 5. ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•
network = keras.Sequential([
    keras.layers.Dense(16, activation='relu', input_shape=(4,)),   # ì…ë ¥ì¸µ + íˆë“ 1
    keras.layers.Dense(8, activation='relu'),                      # íˆë“ 2 - ì¶”ê°€ ê°€ëŠ¥
    keras.layers.Dense(3, activation='softmax')                    # ì¶œë ¥ì¸µ: í´ë˜ìŠ¤ 3ê°œ
])

# 6. ì»´íŒŒì¼
network.compile(
    optimizer='rmsprop',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 7. í•™ìŠµ
history = network.fit(X_train, y_train, epochs=3, batch_size=100)

# 8. í‰ê°€
test_loss, test_acc = network.evaluate(X_test, y_test)
print(f'\nğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}, ì†ì‹¤: {test_loss:.4f}')

# ëª¨ë¸ êµ¬ì„± ìš”ì†Œ ì„¤ëª…
# StandardScaler: íŠ¹ì„±ê°’ë“¤ì„ ì •ê·œí™”í•´ì„œ í•™ìŠµ ì„±ëŠ¥ í–¥ìƒ
# to_categorical: ë‹¤ì¤‘ í´ë˜ìŠ¤ë‹ˆê¹Œ one-hot ì¸ì½”ë”© í•„ìš”
# Dense: ì™„ì „ì—°ê²°ì¸µ, í™œì„±í™” í•¨ìˆ˜ëŠ” reluì™€ softmax
# categorical_crossentropy: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì— ê¼­ í•„ìš”í•œ ì†ì‹¤í•¨ìˆ˜
# batch_size=100: ë°ì´í„°ê°€ 150ê°œë¿ì´ë¼ 100ì€ ê±°ì˜ ì „ì²´ ë°°ì¹˜
# epochs=3: ë°˜ë³µíšŸìˆ˜ ì ê²Œ ì¤˜ì„œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥