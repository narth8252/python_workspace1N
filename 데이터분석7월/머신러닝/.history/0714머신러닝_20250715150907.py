#0714 AM9:30 머신러닝 처리순서 정리. 자주읽어라. 책한권요약
#한빛미디어 파이썬라입러리를 활용한 머신러닝 책추천(보라색+도마뱀)
#책읽다가 모르면 건너뛰고 뒤로 쭉 읽으면서 속도내라.
#뒤에가면 아맞다!하면서 또읽고 또읽고 반복하면 머리속에 들어온다.
"""
✅기초통계
1. 현재상황을 정리하는것, 어떤 집단의 성격을 통계량 통해서 알아낸다.
2. 평균, 분산, 표준편차, 중간값, 최빈값 등으로 알아낸다.
  • 평균 = 모든요소의 합/전체데이터개수 ()
  • ex.연평균 동해안바다온도 작년보다 높아짐- 50년치
3. 평균만으로는 예측힘들더라- 올해가 작년보다 기온높은이유? 엘니뇨나 태풍이 많았다
  • 오차 - 기대값(예상값)과 평균값의 차이의 합은 0
  • 분산 - 오차의 제곱의 합, 절대값 안쓰고 제곱쓴 이유는 오차 커보이라고
    표준분산: 통계학자들이 표본중에서 몇개만 뽑아볼거라서 자유도라고 함
            (기대값-평균값)의 제곱의 합/(n-1)
    사이킷런은 대충 n개로 나눔
  • 표준편차 - 분산의 제곱근, 데이터흩어짐의 정보, boxplot으로 보면 네모가 크게 나타남
            평균, 표준편차: 평균은 같은데 표준편차가 크다라는 의미는 데이터가 극단적이다.
            ex1.어떤학생 모의고사가 평균60점, 표준편차20 : 40~80점 사이를 점수가 왔다갔다하니까.입시때 모험가능
            ex2.다른학생 모의고사가 평균70점, 표준편차 5 : 65~75점 사이에 있으니 안정적이다.
            ex3.공장불량률은 평균보다는 표준편차가 적어야한다.
  • 중간값: 말그대로 중간에 위치한값(데이터11개이면)
            1 2 3 4 5 6 7 8 9 10 11  중간값=(5번째값+6번째값)/2
  표준편차가 크다 → 이상치(튀는값)있을시 평균왜곡가능(연봉평균시 몇십억이랑 몇천만원을 같이 넣는다.)
  이경우 대표값으로 중간값 사용
4. 평균값 중요한 경우
범주형자료(카테고리타입): 불연속적인 값, ex.연비등급(1~4등급)시 중간값은 중요하지않다.
                    발생빈도수(frequeny)가 가장중요, 분할표(DataFrame:value_counts, NumPy:unique,)
                    ex.100대의 차검사해서
                      등 급  1등급  2등급  3등급  4등급
                      차량수   5     10    60     25
                    


✅추론통계 : 기초통계를 바탕으로 예측할때(머신러닝,딥러닝)

1. 타겟이 분류나 회귀냐
회귀의 목적은 연속값 1개 맞춤, 키나 집값, 성적도 점수로 맞추면 회귀
분류는 이진,다중분류, 확률, 무언가가 되거나 합격할 확률, 개나 고양이일 확률
        이진분류(둘중하나), 다중분류(여러개중 하나)
        ex.스마트팜: boxplot, 산포도(히트맵), 히스토그램(분류), 분할표(분류)
                    상관계수,
─────────────────────────────
머신러닝 처리순서
1. 불필요한 열제거 PassengerId, Name, SibSp, Parch 지우기 
2. 각필드별 결측치 확인 
   결측치를 열 또는 행 제거
   혹은 지나치게 결측치가 많을 경우 대체값(
    평균,중간(비범주형일때는 평균 또는 중간값),
    최빈값(데이터가 범주형일때) 
   
3. 이상치제거 
4. 중복값제거 
5. 데이터 자체가 잘못들어온 값
    value_counts 함수나 Unique로 체크하기 
    값바꾸기를 시도하거나 행을 삭제 
6. 라벨링 또는 원핫인코딩 
7. 스케일링
9. 학습하고 특성의 개수가 많을 경우는 특성의 중요도 확인
    (DecisionTree 를 많이 사용)
10. 주성분분석
11. 여러가지 모델로 학습하기, GridSearchCV사용도 가능 
─────────────────────────────
✅1.머신러닝 → 기계학습 처리순서
    1)타겟이 분류 또는 회귀
    1-1)분류는 데이터가 반드시 범주형
        타이타닉 생존자 분류하기(생존자: 어린아이,여자,1등선실)
        생존예측(살았냐,죽었냐지, 0.5만큼 죽어있다는 없음)
        암환자 예측(종류예측-카테고리)
    1-2)회귀, 연속적값들, 키나 부동산가격, 대기중 이산화탄소 양 예측
        방사능양 예측
        자동차연비 → 보통의 경우는 회귀수치만 갖고는 알기어려울경우 강제로 구간나누기
                    등급화해서 그때는 분류가 된다.
        회귀는 실수값, 분류는 확률로 결과를 말한다.
    2)회귀 첫모델은 선형회귀모델, 분류의 첫모델은 로지스틱회귀
      y = ax + b #문제의최소화
      x = [1,2,1.6,2.6,3,2,5,7] #x=독립변수
      y = [2,4,6,4.4,7.8,2.4,8] #y=종속변수: x에 의해 영향을 받는 변수
        원칙적으로 y는하나이고, x는 여러개 있을수 있다.
        수많은 독립변수가 있고 그중에 누가 중요한지 모르기때문에 x마다 별도의 기울기(계수)필요
        a와 b는 뭔지모르니 후보집합을 처음에 랜덤생성, 그 후에 공식적용 반복
        y=ax+b(a,b집합에 대해서) 최소제곱법: 오차의 제곱의 합이 최소가 되게하는 a,b찾기
        a,b추정:추세선
        y와 x간의 산포도를 그린후 그 산포도를 예측할수있는 추세선그리기: 선형회귀(기본적으로 결과값 실수)

    로지스틱회귀분석은 선형회귀모델 이용해서 분류하는데 예측해보면 값이 식수가 나온다.
    이 값을 확률로 바꿀 마법의 함수 - 시그모이드 함수결과를 0~1사이에 머무르게끔 만들어준다.
    결과를 확률로 맞춘다.

    휴리스틱분석 : 어림짐작으로 경험으로 분석해나간다. 안맞으면 처음부터 다시한다.
    1. 데이터수집, 어떤 특성이 결과에 영향을 미칠지 아무도 모른다.
       그래서 아무거나 수집해본다.
       결측치 - 어떤 특성이 NaN값이 절반이 넘음, 완전히 특성제거를 할지 아니면 대체값으로 대체할지
       대체값이 평균,중간값(회귀),최빈값(분류) 뭘로 할지 특성의 성격에 따라 다른 결정.
       이상치제거 - 지나치게 이상한값, IQR을 많이 사용
       중복치제거 - 데이터 수집단계에서 잘못된수집
       특성의 타입이 문자열이거나 숫자라도 범주형일경우 카테고리타입 지정필요
       다양한알고리즘으로 데이터 쪼갬
       라벨인코딩(범주의 범위가 작을때), 원핫인코딩(범주의 범위가 클때)
       데이터가 연산(+-*/)가능하게 만들어야함

    2. 모델결정 후 학습
        학습후 결과값을 보고 이 모델이 실제데이터를 맞출지 어떻게 확신할까?
        그래서 적어도 훈련셋/테스트셋으로 나눠서 훈력셋으로 학습하고, 테스트셋으로 테스트하자
        그리고 평가하자. 평가방법도 모델에 score함수로 해봤는데 원래는 정밀평가함수가 따로있다.
        회귀/분류에 따라서 평가방법다름(0714학습예정)
        목표: 일반화: 특정데이터셋에 맞추는것이 아니, 새로운 데이터셋에도 적용돼야함
            과소적합 - 학습이 덜된상태, 훈련셋, 테스트셋 모두 예측률 낮음
                    하지만 원래데이터셋이 너무작아서 작은예측률이 과대적합일수도 있으므로 주의.
            과대적합 - 지나치게 학습많이된 상태, 훈련셋/테스트셋 차이가 많이나서 티남
            1) 데이터셋이 많아야한다. 많으면 예측율 높을수밖에 없음.
               청주에서 6시간동안 청주관측이래 최대비가 내려서 예측을 못해서 큰 사고발생.
               지금같으면 이 데이터가 예측데이터로 들어감
            2) 특성이 너무 많아도 과대적합된다. 특성많아지면 모델내부가 너무 복잡해져서 과대적합.
               그래서 중요특성만 추출(의사결정트리) 등을 통해서 특성을 제거시키거나 
               PCA(주요성분분석)알고리즘 등을 통해서 특성들을 조작(복잡한과정을 거쳐서) new특성을 만들어낸다.
            3) 알고리즙들에 있는 하이퍼파라미터를 조절해 적절값 찾아낸다.
               (그리드서치 - 옵투나나 파이프라인 등을 활용)
               현재 쏘핫알고리즘:서포트벡터머신, 랜덤포레스트(앙상블), 그라디언트부스팅(xgboost)
            4) 스케일링 - 단위 맞춰주기, 서포트벡터머신이랑 딥러닝에 유용

        3. 검증 
        kfold검증, 등등 있음
        """

"""
─────────────────────────────
🟦머신러닝(기계학습) 실전 개념 정리
✅1. 머신러닝의 주요 과제: 분류와 회귀
1-1. 분류(Classification)
  • 정의: 데이터를 미리 정해진 범주(클래스) 중 하나로 분류하는 문제.
  • 특징: 타깃 값(y)은 반드시 범주형이어야 함.
  • 예시: 타이타닉 생존자 분류, 암 종류 예측 등.
  • 결과: 확률로 예측하며, 최종적으로 가장 높은 확률의 범주로 결정.
  • 중요: 0.5만큼 생존/사망 같은 중간값은 없음.

1-2. 회귀(Regression)
  • 정의: 연속적인 수치 값을 예측하는 문제.
  • 특징: 타깃 값(y)은 실수형이어야 함.
  • 예시: 키, 부동산 가격, 대기 중 이산화탄소 양, 자동차 연비, 방사능 양 등.
  • 결과: 연속적인 실수값으로 예측.
  • 참고: 회귀 결과를 구간으로 나누면 등급화하여 분류 문제로 전환 가능.

1-3. 분류와 회귀의 비교
  • 구분	분류	회귀
  • 목적	범주(클래스) 예측	연속적인 수치 예측
  • 예시	생존/사망, 암 종류 등	가격, 연비, 키 등
  • 결과	확률(범주로 결정)	실수값
대표모델	로지스틱회귀	선형회귀

✅2. 대표 모델: 선형회귀와 로지스틱회귀
2-1. 선형회귀(Linear Regression)
  • 목적: 독립변수(x)와 종속변수(y) 사이의 관계를 직선(추세선)으로 모델링.
  • 수식: y=ax+b
y=ax+b
x: 독립변수(여러 개 가능)
y: 종속변수(보통 하나)
a, b: 기울기와 절편(학습을 통해 찾음)
  • 학습: 최소제곱법(오차의 제곱합이 최소가 되게 a, b를 찾음)
  • 활용: 산포도 위에 추세선을 그려 예측.

2-2. 로지스틱회귀(Logistic Regression)
  • 목적: 선형회귀 모델을 기반으로 분류 문제 해결.
  • 문제점: 선형회귀로 예측하면 실수값이 나오므로, 0~1 사이의 확률로 변환 필요.
  • 해결책: 시그모이드 함수로 예측값을 확률로 변환
σ(z)=11+e−z
  • 활용: 확률이 0.5 이상이면 한 클래스, 미만이면 다른 클래스로 분류.

✅3. 데이터 전처리 및 휴리스틱 분석
3-1. 휴리스틱 분석(Heuristic Analysis)
  • 정의: 경험과 직관을 바탕으로 데이터를 분석하며, 결과가 잘 맞지 않으면 반복적으로 접근.
  • 특징: 정형화된 규칙보다는 실무 경험, 빠른 실험을 중시.

3-2. 데이터 전처리 단계
  • 데이터 수집: 어떤 특성이 중요한지 모르므로 다양한 데이터를 폭넓게 수집.
  • 결측치 처리:
결측치가 많으면 해당 특성 제거 고민.
남길 경우, 회귀는 평균/중간값, 분류는 최빈값 등으로 대체.
특성의 성격(숫자/범주형)에 따라 대체 방식 결정.
  • 이상치 제거: 지나치게 벗어난 값(IQR 등 활용) 제거.
  • 중복치 제거: 잘못 중복된 데이터 제거.
                특성 타입 지정: 문자열, 범주형 숫자는 카테고리 타입 지정 필요.
  • 인코딩: 라벨 인코딩(범주 적을 때), 원핫 인코딩(범주 많을 때) 사용.
  • 연산 가능하게 변환: 데이터가 연산(+, -, *, /) 가능하도록 변환.
  • 다양한 알고리즘 적용: 여러 모델을 시도하여 최적의 방법 탐색.

✅4. 모델 결정, 학습, 평가
4-1. 데이터셋 분리와 평가
  • 훈련셋/테스트셋 분리: 모델이 실제 데이터를 잘 맞추는지 확인하려면 데이터를 나누어 평가.
  • 평가 방법: 회귀/분류에 따라 평가 지표 다름(정밀도, 정확도, RMSE 등).

4-2. 일반화, 과소적합과 과대적합
  • 일반화: 새로운 데이터에도 잘 적용되는 모델을 만드는 것.
  • 과소적합(Underfitting): 학습이 덜된 상태. 훈련셋/테스트셋 모두 예측률 낮음.
  • 과대적합(Overfitting): 훈련셋에는 잘 맞지만 테스트셋에는 예측률이 크게 떨어짐.
데이터가 너무 적거나 특성이 너무 많을 때 발생.
복잡한 모델, 불필요한 특성, 데이터 부족 등이 원인.

4-3. 과대적합 방지 방법
  • 데이터셋 확장: 데이터가 많을수록 예측률 개선.
  • 특성 선택/축소: 의사결정트리, PCA 등으로 중요 특성만 추출하거나 차원 축소.
  • 하이퍼파라미터 튜닝: 그리드서치 등으로 최적값 탐색.
  • 스케일링: 단위 맞추기(특히 SVM, 딥러닝에 유용).

✅5. 모델 검증
K-폴드 교차검증: 데이터를 k개로 나누어 여러 번 학습/평가를 반복, 모델의 일반화 성능을 높임.
기타 검증법: Stratified K-Fold, LOOCV 등 다양한 검증 방식 존재.

이런 흐름으로 머신러닝 실전 프로젝트가 진행됩니다.
각 단계마다 데이터와 모델의 특성을 고려해 적절한 전처리, 모델링, 평가, 검증을 반복하며 최적의 결과를 찾아가는 것이 핵심입니다.
─────────────────────────────
"""

#California Housing 데이터셋에 "회귀문제"를 Optuna 사용해 최적화,모델평가,시각화 → 모델성능,특성 분석
#주택 가격(연속값)을 예측하는 회귀(Regression) 문제
# 회귀문제에 적합한 평가지표: RMSE(Root Mean Squared Error), MAE(Mean Absolute Error), R²(결정계수) 등
#RMSE를 사용한 구체적인 이유:
# 1. 연속값 예측 평가:
#  • Accuracy는 예측이 정확히 맞았는지(1) 틀렸는지(0)만 평가하므로 연속값 예측에는 부적합합니다.
#  • RMSE는 예측값과 실제값 사이의 차이(오차)를 직접 측정하므로 회귀 문제에 적합합니다.
# 2. 오차의 크기 반영:
#  • RMSE는 오차를 제곱하기 때문에 큰 오차에 더 큰 페널티를 부여합니다.
#  • 주택 가격과 같은 중요한 예측에서는 큰 오차를 줄이는 것이 중요합니다.
# 3. 원래 스케일로 해석 가능:
#  • RMSE는 원래 타겟 변수(주택 가격)와 같은 단위로 표현되어 직관적으로 해석이 가능합니다.
#  • 예: RMSE가 0.5라면, 평균적으로 예측 주택 가격이 실제 가격과 0.5 단위 차이가 난다는 의미입니다.
# 회귀 문제에서 자주 사용하는 다른 평가 지표들:
# 1. MAE(Mean Absolute Error):
#  • 절대 오차의 평균으로, 이상치에 덜 민감합니다.
#  • RMSE보다 해석이 더 직관적일 수 있습니다.
# 2. R²(결정계수):
#  • 모델이 설명할 수 있는 타겟 변수 분산의 비율을 나타냅니다.
#  • 0~1 사이의 값으로, 1에 가까울수록 모델 성능이 좋음을 의미합니다.

#코딩순서:
#1. 데이터 로딩 및 탐색:
# • California Housing 데이터셋을 로드하고 기본 정보 확인
# • 데이터를 훈련/테스트 세트로 분할 (80/20)
#2. Optuna 최적화:
# • 회귀 문제이므로 RandomForestRegressor 사용
# • 하이퍼파라미터: n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features
# • 목표 지표: RMSE(Root Mean Squared Error) 최소화
#3. 최적 모델 평가:
# • RMSE, MAE(Mean Absolute Error), R²(결정계수) 계산
# • 최적 모델의 성능 평가 및 특성 중요도 분석
#4. 시각화:
# • 특성 중요도 시각화: 어떤 특성이 예측에 가장 중요한지 파악
# • 실제값 vs 예측값: 모델이 얼마나 정확하게 예측하는지 시각화
# • 잔차 분석: 예측 오차의 분포와 패턴을 확인하여 모델의 한계점 파악
