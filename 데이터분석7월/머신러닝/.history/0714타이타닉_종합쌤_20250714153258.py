import pandas as pd
import numpy as np
import os #íŒŒì¼ì´ë‚˜ í´ë”ê²½ë¡œ ì§€ì •ì‹œ í•„ìš”

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# -------------------------------------------------
# âœ” STEP 1  â”€â”€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° & í•„ìš” ì—†ëŠ” ì—´ ì œê±°
# -------------------------------------------------
# path = r"C:\Users\Admin\Documents\GitHub\python_workspace1N\ë°ì´í„°ë¶„ì„7ì›”\data"
train = pd.read_csv("./data/titanic_train.csv")
test  = pd.read_csv("./data/titanic_test.csv")

#1.ë¶ˆí•„ìš”í•œì—´ì‚­ì œ
print("---------1.ë¶ˆí•„ìš”í•œì—´ì‚­ì œ-----------------") 
print(train.head()) #ì›ë³¸ë°ì´í„° inplace=Trueì•ˆë¨¹íˆëŠ”í•¨ìˆ˜ë§ì•„ ë°˜í™˜ê°’ë°›ê³  shpeì°ì–´ì„œ í™•ì¸
# DROP_COLS = ["PassengerId", "Name", "Ticket", "SibSp", "Parch"]
train=train.drop(columns=["PassengerId", "Name", "Ticket", "SibSp", "Parch", "Cabin"])
test=test.drop(columns=["PassengerId", "Name", "Ticket", "SibSp", "Parch", "Cabin"])
print(train.head())
print(train.shape) #íŠ¹ì„±4ê°œ ì‚­ì œí•¨


#2.ê²°ì¸¡ì¹˜ í™•ì¸í›„ ëŒ€ì²´
print("---------2.ê²°ì¸¡ì¹˜ í™•ì¸ í›„ ëŒ€ì²´-----------------") 
print(train.isna().sum()) #ê°íŠ¹ì„±ë³„ë¡œ NaNê°œìˆ˜ ì¶œë ¥
#Ageë‚˜ EmbarkedëŠ” ëŒ€ì²´
print(train.info())
print(train.describe()) #í‰ê· ê°’, ì¤‘ê°„ê°’, ìµœë¹ˆê°’ ë“± ë­ê°€ ë‚˜ì„ì§€ ì§€ì •í•˜ê¸° ìœ„í•´ ì¨ë³´ì

#2-1.AgeëŠ” mean=í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
age_mean = train["Age"].mean() #mean=í‰ê· ê°’
train['Age'].fillna(age_mean, inplace=True) #ë°˜í™˜ê°’ì´ ì•„ë‹Œ ìê¸°ìì‹ ì´ ë°”ë€œ
test['Age'].fillna(age_mean, inplace=True) #ë°˜í™˜ê°’ì´ ì•„ë‹Œ ìê¸°ìì‹ ì´ ë°”ë€œ
print(train['Age'].isna().sum())
print(train.isna().sum())
print(test.isna().sum())

#2-2.EmbarkedëŠ” ë°ì´í„°ë¬´ì˜ë¯¸í•˜ë‹ˆ í–‰ì‚­ì œ
#í–‰ì¤‘ì— í•œì»¬ëŸ¼ì´ë¼ë„ NaNê°’ìˆìœ¼ë©´ ì „ì²´í–‰ ì‚­ì œ
train = train.dropna(axis=0, how='any')
test = test.dropna(axis=0, how='any')

# for df in (train, test):
#     df["Age"].fillna(df["Age"].mean(), inplace=True)           # ì—°ì†í˜• â†’ í‰ê· 
#     df["Fare"].fillna(df["Fare"].median(), inplace=True)       # ì—°ì†í˜• â†’ ì¤‘ì•™ê°’
#     df["Embarked"].fillna(df["Embarked"].mode()[0], inplace=True)  # ë²”ì£¼í˜• â†’ ìµœë¹ˆê°’
#     df["Cabin"] = df["Cabin"].fillna("N").str[0]               # ê²°ì¸¡ â†’ 'N', ì•ê¸€ìë§Œ

#3.ì´ìƒì¹˜ ì œê±° boxplotê·¸ë¦¬ê¸°(IQR 1.5ë°° ë°”ê¹¥ê°’)
print("---------3.ì´ìƒì¹˜ ì œê±°(boxplot)-----------------")
train.boxplot
# train = remove_outliers(train, ["Age", "Fare"])

#4. ì¤‘ë³µ í–‰ ì œê±°
print("---------4.ì¤‘ë³µ í–‰ ì œê±°-----------------")
# train.drop_duplicates(inplace=True)

# # -------------------------------------------------
# # âœ” STEP 5  â”€â”€ ê°’ ì˜¤ë¥˜ ìˆ˜ì • (ë²”ì£¼í˜• ê°’ ì´ìƒ ì—¬ë¶€ ê²€í† )
# # -------------------------------------------------
# # Sexì™€ Embarkedì˜ ê³ ìœ ê°’ì´ ì˜ˆìƒ ë²”ì£¼ì™€ ë‹¤ë¥´ë©´ ì°ì–´ë³´ê¸°
# for col in ["Sex", "Embarked", "Cabin"]:
#     bad = train[~train[col].isin(train[col].unique())]
#     if not bad.empty:
#         print(f"[WARNING] {col} ì´ìƒê°’:\n", bad[col].value_counts())

# # -------------------------------------------------
# # âœ” STEP 6  â”€â”€ ë¼ë²¨/ì›â€‘í•« ì¸ì½”ë”©
# # -------------------------------------------------
# # Cabin(ì•ê¸€ì), Embarked, Pclass(ë²”ì£¼í˜•)ì€ ì›â€‘í•« / SexëŠ” 0â€‘1 ë§¤í•‘ìœ¼ë¡œ ì²˜ë¦¬
# CATEGORICAL = ["Cabin", "Embarked", "Pclass"]
# BINARY       = ["Sex"]
# NUMERICAL    = ["Age", "Fare"]

# # Sexë¥¼ 0/1ë¡œ
# train["Sex"] = train["Sex"].map({"male": 0, "female": 1})
# test["Sex"]  = test["Sex"].map({"male": 0, "female": 1})

# # -------------------------------------------------
# # âœ” STEP 7  â”€â”€ ìŠ¤ì¼€ì¼ë§ + ëª¨ë¸ íŒŒì´í”„ë¼ì¸
# # -------------------------------------------------
# target = train["Survived"]
# features = train.drop("Survived", axis=1)

# X_train, X_val, y_train, y_val = train_test_split(
#     features, target, test_size=0.2, random_state=42, stratify=target
# )

# # ì»¬ëŸ¼ ë³€í™˜ê¸°
# preprocess = ColumnTransformer(
#     transformers=[
#         ("num", StandardScaler(), NUMERICAL),
#         ("cat", "passthrough",  CATEGORICAL),   # ì›â€‘í•«ì€ get_dummiesë¡œ ë¯¸ë¦¬ í•˜ì§€ ì•Šê³  RFë¼ì„œ ê·¸ëŒ€ë¡œ ë‘¬ë„ ok
#         ("bin", "passthrough",  BINARY)
#     ],
#     remainder="drop"
# )

# rf = RandomForestClassifier(random_state=42)

# pipe = Pipeline(steps=[
#     ("prep", preprocess),
#     ("model", rf)
# ])

# param_grid = {
#     "model__n_estimators": [50, 100, 200],
#     "model__max_depth":    [None, 5, 10],
#     "model__min_samples_split": [2, 5]
# }

# grid = GridSearchCV(pipe, param_grid, cv=5, scoring="accuracy", verbose=1)
# grid.fit(X_train, y_train)

# # -------------------------------------------------
# # âœ” STEP 8  â”€â”€ ì„±ëŠ¥ í‰ê°€ & íŠ¹ì„± ì¤‘ìš”ë„
# # -------------------------------------------------
# best_pipe = grid.best_estimator_
# y_pred = best_pipe.predict(X_val)

# print("ğŸ“Š ìµœì  íŒŒë¼ë¯¸í„°:", grid.best_params_)
# print("âœ… ê²€ì¦ ì •í™•ë„:", accuracy_score(y_val, y_pred))
# print("\nğŸ“„ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\n", classification_report(y_val, y_pred))

# # íŠ¹ì„± ì¤‘ìš”ë„ (íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ì—ì„œ RFê°€ í•™ìŠµëìœ¼ë‹ˆ ê°€ì ¸ì™€ì„œ ì¶œë ¥)
# rf_model = best_pipe.named_steps["model"]
# feature_names = (
#     NUMERICAL                                         # ìŠ¤ì¼€ì¼ë§ëœ ìˆ˜ì¹˜
#     + CATEGORICAL                                     # ê·¸ëŒ€ë¡œ í†µê³¼
#     + BINARY                                          # Sex
# )
# importances = pd.Series(rf_model.feature_importances_, index=feature_names)
# importances.sort_values(ascending=False, inplace=True)

# print("\nğŸ” Feature Importances")
# print(importances.round(3))
